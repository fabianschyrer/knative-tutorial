# Configure Autoscaling

You might have realized that autoscaler in Knative scales down pods to zero after some time. This is actually configurable through annotations. The autoscaler itself is also configurable. [Autoscale Sample](https://github.com/knative/docs/tree/master/serving/samples/autoscale-go) in Knative docs explains the details of autoscaler but let's recap the main points here as well.

There are two autoscaler classes built into Knative: 
1. The default concurrency-based autoscaler which is based on the average number of in-flight requests per pod. 
2. Kubernetes CPU-based autoscaler which autoscales on CPU usage. 

The autoscaling can be bounded with `minScale` and `maxScale` annotations.  

## Disable scale down to zero 

Let's create a new revision `v6` that disables scaling down of pods to zero. 

Create a [service-v6.yaml](../serving/helloworld-csharp/service-v6.yaml) file:

```yaml
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  name: helloworld-csharp
  namespace: default
spec:
  runLatest:
    configuration:
      revisionTemplate:
        metadata:
          annotations:
            # Default: Knative concurrency-based autoscaling with 
            # 100 requests in-flight per pod.
            autoscaling.knative.dev/class:  kpa.autoscaling.knative.dev
            autoscaling.knative.dev/metric: concurrency
            autoscaling.knative.dev/target: "100"

            # Alternative: Kubernetes CPU-based autoscaling.
            # autoscaling.knative.dev/class:  hpa.autoscaling.knative.dev
            # autoscaling.knative.dev/metric: cpu
            
            # Disable scale to zero with a minScale of 1.
            autoscaling.knative.dev/minScale: "1"
            # Limit scaling to 5 pods.
            autoscaling.knative.dev/maxScale: "5"
        spec:
          container:
            # Replace meteatamel with your actual DockerHub
            image: docker.io/meteatamel/helloworld-csharp:v1
            env:
              - name: TARGET
                value: "C# Sample v6"
```

Note the autoscaling annotations. We're keeping the defualt concurrency based autoscaling with the default options. We're simply setting `minScale` to 1 and `maxScale` to 5. This will make sure that there is a single pod at all times.

Apply the change:

```bash
kubectl apply -f service-v6.yaml
```

Check that pod for the service is running:

```bash
kubectl get pods
NAME                                                  READY     STATUS    RESTARTS   
helloworld-csharp-00001-deployment-5865bc498c-w7qc7   3/3       Running   0          
```
And this pod will continue to run, even if there's no traffic. 

## What's Next?
You can try Kubernetes CPU-based autoscaling or move onto [Integrate with Twilio](05-twiliointegration.md)